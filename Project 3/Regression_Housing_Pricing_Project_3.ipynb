{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSuJa_Aa1lL9"
      },
      "source": [
        "# Project 3: Regression Housing Pricing for Fathers who want to buy a House: \n",
        "Predicting Housing Prices\n",
        "\n",
        "In this project you will discover how to develop and evaluate neural network models using Keras for a regression problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hUX_qOm1lMB"
      },
      "source": [
        "<a name=\"1\"></a>\n",
        "## 1 - Packages \n",
        "\n",
        "We will start off by importing all of the classes and functions we will need:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEouUcYerT64",
        "outputId": "53ee8176-d63b-4dc7-85ff-7d6fd1f0bbab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cCAgAxGY1lMC"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "# from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is in fact not in CSV format, the attributes are instead separated by whitespace. We can load this easily using the pandas library. We can then split the input (X) and output (Y) attributes so that they are easier to model with Keras and scikit-learn."
      ],
      "metadata": {
        "id": "DUedIe48yuQK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nkdSl9WE1lMG"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"housing.csv\", delim_whitespace=True, header=None)\n",
        "dataset = dataframe.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:13]\n",
        "Y = dataset[:,13]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we define the function to create the baseline model to be evaluated. It is a simple model that has a single fully connected hidden layer with the same number of neurons as input attributes (13). The network uses good practices such as the rectifier activation function for the hidden layer. No activation function is used for the output layer because it is a regression problem and we are interested in predicting numerical values directly without transform.\n",
        "\n",
        "The efficient ADAM optimization algorithm is used and a mean squared error loss function is optimized. This will be the same metric that we will use to evaluate the performance of the model. It is a desirable metric because by taking the square root gives us an error value we can directly understand in the context of the problem (thousands of dollars).\n"
      ],
      "metadata": {
        "id": "mTyHMjXyy7dA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "194VKcBJ1lMI"
      },
      "outputs": [],
      "source": [
        "# define base model\n",
        "def baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Keras wrapper object for use in scikit-learn as a regression estimator is called KerasRegressor. We create an instance and pass it both the name of the function to create the neural network model as well as some parameters to pass along to the fit() function of the model later, such as the number of epochs and batch size. Both of these are set to sensible defaults.\n",
        "\n",
        "We also initialize the random number generator with a constant random seed, a process we will repeat for each model evaluated in this tutorial. This is an attempt to ensure we compare models consistently.\n"
      ],
      "metadata": {
        "id": "-200knAey_FA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TMAFTOb91lMJ"
      },
      "outputs": [],
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# evaluate model with standardized dataset\n",
        "estimator = KerasRegressor(model=baseline_model, epochs=100, batch_size=5, verbose=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final step is to evaluate this baseline model. We will use 10-fold cross validation to evaluate the mode"
      ],
      "metadata": {
        "id": "iZTQ3gKozHDR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZChGbBIR1lMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16976644-dd91-482f-8db4-56158ae60e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: 0.70 (0.12) MSE\n"
          ]
        }
      ],
      "source": [
        "kfold = KFold(n_splits=10, random_state=seed, shuffle=True)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An important concern with the Boston house price dataset is that the input attributes all vary in their scales because they measure different quantities.\n",
        "\n",
        "It is almost always good practice to prepare your data before modeling it using a neural network model.\n",
        "\n",
        "Continuing on from the above baseline model, we can re-evaluate the same model using a standardized version of the input dataset.\n",
        "\n",
        "We can use scikit-learnâ€™s Pipeline framework to perform the standardization during the model evaluation process, within each fold of the cross validation. This ensures that there is no data leakage from each testset cross validation fold into the training data:\n",
        "\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
        "\n",
        "\n",
        "The code below creates a scikit-learn Pipeline that first standardizes the dataset then creates and evaluates the baseline neural network model.\n"
      ],
      "metadata": {
        "id": "yihjZxk0zLe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model with standardized dataset\n",
        "numpy.random.seed(seed)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasRegressor(model=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = KFold(n_splits=10, random_state=seed, shuffle=True)\n",
        "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
        "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snHwnXUWsO4d",
        "outputId": "20e92d4d-2f20-4eaa-a3e5-6c9a8d336a6e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardized: 0.75 (0.10) MSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A further extension of this step is to similarly apply a rescaling to the output variable such as normalizing it to the range of 0-1 and use a Sigmoid or similar activation function on the output layer to narrow output predictions to the same range."
      ],
      "metadata": {
        "id": "rtt0R0NwzPqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extension: Rescale output variable and use a sigmoid activation function\n",
        "def baseline_model_with_rescaling():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "# evaluate model with standardized dataset and rescaled output\n",
        "rescaled_estimators = []\n",
        "rescaled_estimators.append(('standardize', StandardScaler()))\n",
        "rescaled_estimators.append(('mlp', KerasRegressor(model=baseline_model_with_rescaling, epochs=50, batch_size=5, verbose=0)))\n",
        "rescaled_pipeline = Pipeline(rescaled_estimators)\n",
        "rescaled_results = cross_val_score(rescaled_pipeline, X, Y, cv=kfold)\n",
        "print(\"Standardized with Rescaled Output: %.2f (%.2f) MSE\" % (rescaled_results.mean(), rescaled_results.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e2abd28-2aeb-4dd5-e8ab-c74086281b94",
        "id": "wMqCfbh9vQw4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardized with Rescaled Output: -6.04 (1.60) MSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way to improve the performance of a neural network is to add more layers. This might allow the model to extract and recombine higher order features embedded in the data.\n",
        "\n",
        "In this step we will evaluate the effect of adding one more hidden layer to the model. This is as easy as defining a new function that will create this deeper model, copied from our baseline model above. We can then insert a new line after the first hidden layer. In this case with about half the number of neurons.\n"
      ],
      "metadata": {
        "id": "QjcFYhTi8Mbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "def larger_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))  # Additional hidden layer\n",
        "    model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "numpy.random.seed(seed)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasRegressor(model=larger_model, epochs=50, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = KFold(n_splits=10, random_state=seed, shuffle=True)\n",
        "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
        "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf8n_1LY7-BR",
        "outputId": "7795bd48-6060-45d3-a663-16e174120080"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Larger: 0.80 (0.11) MSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another approach to increasing the representational capability of the model is to create a wider network.\n",
        "\n",
        "In this section we evaluate the effect of keeping a shallow network architecture and nearly doubling the number of neurons in the one hidden layer.\n",
        "\n",
        "Again, all we need to do is define a new function that creates our neural network model. Here, we have increased the number of neurons in the hidden layer compared to the baseline model from 13 to 20.\n"
      ],
      "metadata": {
        "id": "oCwNu8Pm8S1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define wider model\n",
        "def wider_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu'))  # Increase the number of neurons to 20\n",
        "    model.add(Dense(1, kernel_initializer='normal'))\n",
        "    \n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "numpy.random.seed(seed)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasRegressor(model=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = KFold(n_splits=10, random_state=seed, shuffle=True)\n",
        "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
        "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBV9cN2b8FNM",
        "outputId": "9d2711c6-223e-42cc-88e0-6fd07f075520"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wider: 0.83 (0.08) MSE\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}